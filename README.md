# Neural Style Transfer for Modeling Artistic Images using VGG19

In this paper we discuss about the Neural Style transfer. Neural style transfer is an optimization technique that takes in two images an input content image and an input style image and renders an image that mimics the content of the content image and also imbibes the style of the reference style image[1]. The implementation of neural style transfer involves the usage of VGG 19 model pretrained on ImageNet. Each layer of VGG 19 extracts feature information from the images, using this feature information we define content loss and style loss. The Content and Style loss functions are used to determine the difference in content and style with respect to the reference images. By using the loss functions with suitable optimiziters like Adam and SGD we can render visualizations that is a combination of two different images.
